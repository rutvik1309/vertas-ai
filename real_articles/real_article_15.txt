New York CNN —

A measure tucked in President Donald Trump’s sweeping domestic policy bill making its way through Congress would effectively block states from enforcing artificial intelligence-related regulations for the next decade, a rule that’s alarming some followers of the tech world.

The proposed moratorium comes as AI extends into more areas of Americans’ lives — from health care and law enforcement to personal relationships and hiring. And despite Silicon Valley’s promises of super intelligence that solves the world’s problems, AI also poses major risks, such as putting humans out of work and spreading lies.

There’s no overarching federal law regulating AI, although Trump recently signed the Take It Down Act, which criminalizes sharing non-consensual explicit images, including those made by AI. But various states have passed AI laws, including around the use of deepfakes in elections and AI discrimination in hiring.

Those state laws would likely become unenforceable if Senate Republicans’ version of the “big, beautiful bill” makes it to President Donald Trump’s desk. Earlier this month, Senate Commerce Committee Republicans tied compliance with the moratorium to crucial federal funds for deploying internet infrastructure.

The tech world has been divided on a state regulation pause: Some want to avoid a patchwork of state regulations, while others have opposed the proposed moratorium. The provision has also drawn backlash from academics, tech workers, advocacy groups and even some lawmakers.

Among the opposition is a bipartisan group of 40 attorneys general who wrote to Congress last month urging lawmakers not to pass the moratorium, including North Carolina Attorney General Jeff Jackson.

“Years from now, it could end up being the big story out of this reconciliation bill,” Jackson, who also represented North Carolina in Congress from 2023 to 2024, said in an interview with CNN earlier this week.

Jackson detailed his concerns about the moratorium and why he’s skeptical Congress will pass broad AI regulations. This conversation has been lightly edited for length and clarity.

Duffy: What was your initial reaction to learning that this AI moratorium was part of the bill?

Attorney General Jeff Jackson: I got a call from another attorney general, right when the reconciliation bill had just dropped. And they said, “You’ve got to take a look at this provision.” And so I pulled it up and shared their concern, basically, that this is an incredibly broad new rule that would have cascading unintended consequences.

Duffy: What are you and other attorneys general concerned will happen if this passes?

Jackson: The first order consequence is it will effectively seek to repeal a number of consumer and voter protections that have been put in place by a handful of states to guard people against being intentionally fooled by the abusive use of AI by bad actors. The second order consequence is potentially far greater, because it’s all the ways that AI will end up being weaponized by bad actors over the next decade that we can’t possibly predict today. And the prospect of not being able to defend people against those bad actors is extremely disconcerting.

If you look at the current AI laws on the books, they’re pretty narrowly targeted to voter protection and consumer protection. It’s stuff like, people can’t digitally clone your face and voice without your consent. I think that’s something that enjoys very broad support.

I mean, (AI) is going to become misinformation on steroids, even if we have safeguards against it. I just can’t imagine a world in which there is no legal recourse against deepfakes being created for the purpose of fooling tens of millions of voters.

A provision in Republicans' domestic policy bill could prevent states from regulating AI, raising concerns for some that tech companies won't be held accountable for potential harms to society. Nathan Howard/Reuters

Duffy: Are there laws in North Carolina specifically that you’re worried about losing the ability to enforce?

Jackson: There are. They are more in the criminal realm. But my larger concern is how this is going to tie our hands going forward.

My main concern here, really, is that I don’t think Congress is going to put up any safeguards. My level of confidence in Congress following through on what they say they want to do in erecting some national safeguards is just very low, and I think that’s well earned. They didn’t put up any safeguards with respect to the internet or privacy or social media, not even with respect to protecting kids. And now they’re saying, “Hey, we know we failed at that, but trust us, we’re going to get it right this time.” And I think we all know that AI is more complicated than any of those issues because of the multitude of ways that it can be used and will end up being integrated into our lives and our economy.

If this were a simple choice between a patchwork approach with 50 states or a single, national set of safeguards, that would be a legitimate question, but I don’t think that’s the actual choice. The actual choice in the reality we currently inhabit is between allowing states to put up safeguards or doing nothing. And I simply cannot imagine doing nothing, and being locked into doing nothing for the next decade.

Duffy: When it comes to AI, what makes you concerned that Congress won’t act? I ask because we recently saw the Take It Down Act signed into law, where there was bipartisan agreement that this specific use of the technology was dangerous. Do you think that we need something broader, and that’s what you think Congress isn’t going to be able to act on here?

Jackson: I’ve served in Congress, and I saw dozens of AI bills get filed that were narrowly targeted and I think would enjoy broad support, and none of them passed. We heard from (Republican) majority leadership in the House that, categorically, no AI bills were going to pass. It was a matter of stated policy by majority party leadership that they were going to block all of those bills, and they did so.

Part of my extreme skepticism of Congress doing anything substantial here is based on the history, the clear record of failure when it comes to privacy, the internet and social media, and part of it is from recent history of having served in that body and being told they simply were not interested in doing anything significant.

Duffy: Why is that?

Jackson: All I know is that there’s a mix of reasons. Some of those have to do with technological innovation, and some of them have to do with very powerful lobbyists.

Duffy: On that note, we hear from the tech companies this argument that the US risks falling behind China in AI if there is too much regulation. What do you make of that argument?

Jackson: I think it’s perfectly reasonable to be concerned with over-regulation of a nascent technology that’s going to be economically transformative. However, if we’re weighing that against being locked in to doing literally nothing for the next decade, that’s a major concern.